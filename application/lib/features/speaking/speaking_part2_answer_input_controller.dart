import 'dart:async';

import 'package:flutter/foundation.dart';
import 'package:flutter/material.dart';
import 'package:ielts_ai_trainer/features/speaking/domain/speaking_answer_repository.dart';
import 'package:ielts_ai_trainer/features/speaking/domain/speaking_speech_answer.dart';
import 'package:ielts_ai_trainer/features/speaking/domain/speaking_utterance_id_vo.dart';
import 'package:ielts_ai_trainer/features/speaking/domain/speaking_utterance_vo.dart';
import 'package:ielts_ai_trainer/features/speaking/utterance_recording_service.dart';
import 'package:ielts_ai_trainer/shared/domain/prompt_topic.dart';

/// Controller for SpeakingAnswerInputScreen.
class SpeakingPart2AnswerInputController extends ChangeNotifier {
  /// Repository for user answers related to speaking tasks.
  final SpeakingAnswerRepository _repo;

  /// The start time used to calculate the elapsed duration.
  late DateTime _startTime;

  /// Timer used to track the elapsed duration.
  late Timer _timer;

  /// Elapsed time since the timer started.
  Duration _elapsed = const Duration();

  /// The prompt text generated by the question generator screen.
  final String _promptText;

  /// The topics used to generate the prompt.
  final List<String> _topics;

  /// The service to record the user's speech.
  late final UtteranceRecordingService _recordingSrv;

  /// The answer text the user entered.
  String _answerText = '';

  /// The note text the user entered.
  String _noteText = '';

  /// Whether the note input is locked.
  bool _isNoteLocked = false;

  /// Whether the note input has been automatically locked after 1 minute.
  bool _isNoteAutoLocked = false;

  /// The recording state: 0 = not started, 1 = recording, 2 = stopped, 3 = rerecording.
  int _recordingState = 0;

  /// The playing state: 0 = stop, 1 = playing.
  int _playingState = 0;

  // The UUID of the audio file currently being recorded.
  String _recordingFileUuid = '';

  SpeakingPart2AnswerInputController({
    required SpeakingAnswerRepository speakingAnswerRepository,
    required String promptText,
    required List<String> topics,
  }) : _repo = speakingAnswerRepository,
       _promptText = promptText,
       _topics = topics {
    _recordingSrv = UtteranceRecordingService(
      onPlayerComplete: _onPlayerComplete,
    );
  }

  String get answerText => _answerText;

  String get noteText => _noteText;

  Duration get elapsed => _elapsed;

  bool get isNoteLocked => _isNoteLocked;

  bool get isSubmitButtonEnabled => _answerText.isNotEmpty;

  bool get isNoteEnabled => !_isNoteLocked;

  bool get isRecordingButtonEnabled => _answerText.isNotEmpty;

  /// Returns the elapsed duration since the timer started.
  Duration get _elapsedDuration {
    final msec =
        DateTime.now().millisecondsSinceEpoch -
        _startTime.millisecondsSinceEpoch;
    return Duration(milliseconds: msec);
  }

  /// Returns the remaining duration to enter a note since the timer started.
  Duration get _remainingNoteDuration {
    final msec =
        Duration(minutes: 1).inMilliseconds -
        (DateTime.now().millisecondsSinceEpoch -
            _startTime.millisecondsSinceEpoch);
    return Duration(milliseconds: msec);
  }

  /// Returns the elapsed time for display.
  String get elapsedAsText {
    final elapsed = _elapsed;
    final m = elapsed.inMinutes.toString().padLeft(2, '0');
    final s = (elapsed.inSeconds % 60).toString().padLeft(2, '0');
    return "Time: $m:$s";
  }

  /// Returns the remaining time to enter the Note for display.
  String get remainingAsText {
    final remaining = _remainingNoteDuration;
    final absRemaining = remaining.abs();
    final m = absRemaining.inMinutes.toString().padLeft(2, '0');
    final s = (absRemaining.inSeconds % 60).toString().padLeft(2, '0');
    return '${remaining.isNegative ? '-' : ''}$m:$s';
  }

  /// Returns the current entered word count and recommended word count.
  String getWordCountAsText() {
    // Consider apostrophes as part of a word (e.g., "it's" counts as one word).
    final length = RegExp(r"\b[\w']+\b").allMatches(_answerText).length;
    return "Words: $length";
  }

  bool get isNotRecorded => _recordingState == 0;

  bool get isRecording => _recordingState == 1;

  bool get isRecorded => _recordingState == 2;

  bool get isReRecording => _recordingState == 3;

  bool get isPlaying => _playingState == 1;

  bool get isStop => _playingState == 0;

  set answerText(String value) {
    _answerText = value.trim();

    notifyListeners();
  }

  set noteText(String value) {
    _noteText = value.trim();

    notifyListeners();
  }

  set isNoteLocked(bool value) {
    _isNoteLocked = value;

    notifyListeners();
  }

  /// Starts the duration timer.
  void startTimer() {
    _startTime = DateTime.now();
    _timer = Timer.periodic(const Duration(seconds: 1), (_) {
      _elapsed = _elapsedDuration;

      // Disables the Note input area when the time after 1 minute.
      // This operation is done only once.
      if (!_isNoteAutoLocked && _elapsed > const Duration(minutes: 1)) {
        _isNoteLocked = true;
        _isNoteAutoLocked = true;
      }
      notifyListeners();
    });
  }

  /// Stops the duration timer.
  void cancelTimer() {
    _timer.cancel();
  }

  /// Saves the user's answer.
  Future<int> saveUserAnswer() async {
    final now = DateTime.now();

    final topics = <PromptTopic>[];
    for (var i = 0; i < _topics.length; i++) {
      topics.add(PromptTopic(order: (i + 1), title: _topics[i]));
    }

    final answer = SpeakingSpeechAnswer(
      createdAt: now,
      prompt: SpeakingUtteranceVO(order: 1, isUser: false, text: _promptText),
      answer: SpeakingUtteranceVO(order: 2, isUser: true, text: _answerText),
      isGraded: false,
      duration: _elapsedDuration.inSeconds,
      topics: topics,
      updatedAt: now,
      note: _noteText,
    );

    final ids = await _repo.saveSpeakingSpeechAnswer(answer);

    // Persists the temporary recording file.
    if (_recordingFileUuid.isNotEmpty) {
      try {
        _persistRecordingFile(ids.utteranceId);
      } catch (e, stackTrace) {
        await _repo.deleteSpeakingUserAnswer(ids.id); // rollback
        throw Exception('Failed to persist recording file: $e\n$stackTrace');
      }
    }

    return ids.id;
  }

  /// Deletes the temporary recording file.
  Future<void> deleteTemporaryRecordingFile() async {
    if (_recordingFileUuid.isNotEmpty) {
      await _recordingSrv.deleteTemporaryRecordingFile(_recordingFileUuid);
      _recordingFileUuid = '';
    }
  }

  /// Starts recording the user's speech.
  Future<void> startRecording() async {
    await deleteTemporaryRecordingFile();
    _recordingState = isRecorded ? 3 : 1;
    _recordingFileUuid = await _recordingSrv.startRecording();

    notifyListeners();
  }

  /// Stops the curerntly recording.
  Future<void> stopRecording() async {
    if (isRecording || isReRecording) {
      await _recordingSrv.stopRecording();
      _recordingState = 2;
    }

    notifyListeners();
  }

  /// Starts playing the recorded speech.
  Future<void> startPlaying() async {
    _playingState = 1;
    await _recordingSrv.playAudio(_recordingFileUuid);
    notifyListeners();
  }

  /// Stops playing the currently playing recorded speech.
  Future<void> stopPlaying() async {
    _playingState = 0;
    await _recordingSrv.stopAudio();
    notifyListeners();
  }

  /// Called when the play stops.
  void _onPlayerComplete() {
    _playingState = 0;
    notifyListeners();
  }

  /// Persists the temporary recording file for an utterance.
  Future<void> _persistRecordingFile(SpeakingUtteranceIdVO utteranceId) async {
    await _recordingSrv.persistRecordingFile(utteranceId, _recordingFileUuid);
  }
}
